{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for eggNOG5 class-predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional network (similar to DeepFam) trained on eggNOG5 classes on bacterial level. Architecture conceived by Roman for multiclass-classification on eggNOG5 and pfam classes, adapted by Lukas to focus on single-task classification of eggNOG5 labels. Adaption due to increasing training data using only eggNOG5 as well as comparability with DeepFam architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/gosch/anaconda3/envs/py374/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import copy\n",
    "import datetime\n",
    "from functools import partial\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.nn.modules.loss import MSELoss, L1Loss\n",
    "from torch.nn.modules import PairwiseDistance\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from frenetiq.data_loader import collate_sequence_pairs_with_labels\n",
    "from frenetiq.data_loader import SimapDatasetOnline\n",
    "from frenetiq.evaluation import correlation_plot, top_k_accuracy_plot\n",
    "from frenetiq.utils.extract_simap_similarities import S2_NUM_SEQ\n",
    "from frenetiq.utils.misc import tensor_from_csc, count_parameters\n",
    "from frenetiq.network.loss import EuclideanMAELoss, EuclideanMSELoss, ContrastiveLoss\n",
    "from frenetiq.network.tcn import DoubletTCN\n",
    "from frenetiq.network.embedding import AminoAcidWordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc70b6736b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_state = np.random.RandomState(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SIMAP2 data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Loading SIMAP2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reusing previous tmpdir at /tmp/frenetiq/.\n",
      "INFO:root:Loading sequenceids...\n",
      "INFO:root:Trying to load sequenceid_file from /tmp/frenetiq/sequenceids.npz\n",
      "INFO:root:Trying to load sequenceid_file from /cube/proteinUniverse/representation/02_onehot_sequences/simap2_onehot/sequenceids.npz\n",
      "INFO:root:Copying sequence index file /proj/cube/proteinUniverse/data/simap2_sequences.dict.pkl.index_db to TMP at /tmp/frenetiq/...\n",
      "INFO:root:Could not find sequence index file. New index will be created (slow).\n",
      "INFO:root:Reading protein sequences from /proj/cube/proteinUniverse/data/simap2_sequences.dict.pkl...\n",
      "INFO:root:Loading labels from /proj/cube/deepfam/data/eggNOG5/simap2_eggnog5_bacteria_singlelabel_keep-False_classsize-10000.hdf\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "INFO:root:Not all of train/val/test_ind were specified. Using a predefined splitting strategy.\n",
      "INFO:root:train_ind.shape=(16213,), val_ind.shape=(1802,),test_ind.shape=(2002,).\n"
     ]
    }
   ],
   "source": [
    "class_size = 10000\n",
    "simap_dataset = SimapDatasetOnline(\n",
    "    max_hits=100, #ignored\n",
    "    sequence_file='/proj/cube/proteinUniverse/data/simap2_sequences.dict.pkl',\n",
    "    use_similarity=False,  # don't fetch SIMAP2 scores, to speed things up\n",
    "    labels_file=f'/proj/cube/deepfam/data/eggNOG5/simap2_eggnog5_bacteria_singlelabel_keep-False_classsize-{class_size}.hdf',\n",
    "    verbose=3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16213"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simap_dataset.phase = 'train'\n",
    "n_train = len(simap_dataset)\n",
    "n_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available? True, thus device=cuda\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if cuda else 'cpu')\n",
    "\n",
    "print(f'CUDA available? {cuda}, thus device={device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DeepFamLike(nn.Module):\n",
    "    \"\"\" Convolutional network for protein family prediction on eggNOG5 classes.\n",
    "\n",
    "    The architecture is based on DeepFam, with some changes (encoding,\n",
    "    activation functions, output layers, etc.)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ...\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes: List[int], encoding_dim: int = 5, \n",
    "                 kernel_size: int = 3, n_filters: int = 1_000, \n",
    "                 dropout: float = 0.2, embedding_layer_type: str = 'max'):\n",
    "        super(DeepFamLike, self).__init__()\n",
    "\n",
    "        # Encoding of amino acid sequence to vector space\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.encoding = AminoAcidWordEmbedding(embedding_dim=encoding_dim,\n",
    "                                               k=1)\n",
    "\n",
    "        # Convolutional layer\n",
    "        self.conv1 = nn.Conv1d(in_channels=encoding_dim,\n",
    "                               out_channels=n_filters,\\\n",
    "                               kernel_size=kernel_size, )\n",
    "        # Non-linearity\n",
    "        self.activation1 = nn.SELU()\n",
    "\n",
    "        # Regularization with dropout (alph/proj/cube/deepfam/dev/savesa dropout for SELU activations)\n",
    "        # DON'T forget to set model to train/eval mode!\n",
    "        self.dropout1 = nn.AlphaDropout(p=dropout)\n",
    "\n",
    "        # Embedding layer\n",
    "        if 'avg' in embedding_layer_type:\n",
    "            self.embedding1 = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        elif 'max' in embedding_layer_type:\n",
    "            self.embedding1 = nn.AdaptiveMaxPool1d(output_size=1)\n",
    "        else:\n",
    "            raise ValueError(f'Unknown embedding_layer_type: {embedding_layer_type}')\n",
    "\n",
    "        # Classifcation layer\n",
    "        self.classification1 = nn.Linear(in_features=n_filters, out_features=n_classes[0])\n",
    "\n",
    "        # Initialize weights for SELU activation\n",
    "        self.conv1.weight.data.normal_(0.0, np.sqrt(1. / np.prod(self.conv1.kernel_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoding(x).permute(0, 2, 1).contiguous() #s.t. sum over filter size is a sum over contiguous memory blocks\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.embedding1(x)\n",
    "        x = x.view(-1, self.conv1.out_channels)\n",
    "        out = self.classification1(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "collated_batch = namedtuple('collated_batch', ['query', 'hits', 'similarity', 'query_labels', 'hits_labels'])\n",
    "\n",
    "#Gosch: Note batch is actually a list of namedtuples not a namedtuple\n",
    "def collate_sequences_with_labels(batch: namedtuple, zero_padding: bool = False, random_padding: bool = False,\n",
    "                                  skip_identical: bool = True) -> namedtuple:\n",
    "    \"\"\" Collate query and (optionally) labels. \"\"\"\n",
    "\n",
    "    # Find the longest sequence, in order to zero pad the others; and optionally skip self hits\n",
    "    max_len, n_features = 0, 1  # batch.query_encoded.shape\n",
    "    n_data = 0\n",
    "    for b in batch:\n",
    "        query = b.query_encoded\n",
    "        n_data += 1\n",
    "        sequence_len = len(query)\n",
    "        if sequence_len > max_len:\n",
    "            max_len = sequence_len\n",
    "\n",
    "    # Collate the sequences\n",
    "    if zero_padding:\n",
    "        sequences = np.zeros((n_data, max_len,), dtype=np.int)\n",
    "        for i, b in enumerate(batch):\n",
    "            query = np.array(b.query_encoded)\n",
    "            # If selected, choose randomly, where to insert zeros\n",
    "            if random_padding and len(query) < max_len:\n",
    "                n_zeros_1 = max_len - len(query)\n",
    "                start1 = np.random.choice(n_zeros_1 + 1)\n",
    "                end1 = start1 + len(query)\n",
    "            else:\n",
    "                start1 = 0\n",
    "                end1 = len(query)\n",
    "\n",
    "            # Zero pad and / or slice\n",
    "            sequences[i, start1:end1] = query[:].T\n",
    "        sequences = default_collate(sequences)\n",
    "    else:  # no zero-padding, must use minibatches of size 1 downstream!\n",
    "        raise NotImplementedError\n",
    "        sequences = [torch.from_numpy(x) for x in batch.hits_encoded]\n",
    "\n",
    "    # Collate the labels\n",
    "    labels = np.array([b.query_labels for b in batch], dtype=np.int)\n",
    "    labels = default_collate(labels)\n",
    "\n",
    "    return collated_batch(query=sequences,\n",
    "                          hits=None,\n",
    "                          similarity=None,\n",
    "                          query_labels=labels,\n",
    "                          hits_labels=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: early_stopping is for debugging not regularization technique!\n",
    "def train_model(model, criterion, optimizer, scheduler, data_loader, num_epochs=2,\n",
    "                tensorboard_exp=None, batch_size: int = None, early_stopping: int = None,\n",
    "                log_interval: int = 100, validation_only: bool = False):\n",
    "    # Try to set up tensorboard\n",
    "    if tensorboard_exp is not None:\n",
    "        exp = tensorboard_exp + '_' + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        param_str = exp\n",
    "        #tb_dir = f'/dev/shm/tensorboard/{exp}'\n",
    "        tb_dir = f'/proj/cube/deepfam/dev/tensorboard/{exp}'\n",
    "        tensorboard_writer = SummaryWriter(tb_dir)\n",
    "        print(f'Tensorboard directory:', tensorboard_writer.log_dir)\n",
    "    else:\n",
    "        tensorboard_writer = None\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            # Don't forget to set SIMAP dataset phase\n",
    "            data_loader.dataset.phase = phase\n",
    "            if phase == 'train':\n",
    "                if validation_only:\n",
    "                    continue\n",
    "                else:\n",
    "                    model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_corrects = 0.\n",
    "\n",
    "            log_loss = 0.\n",
    "            log_corrects = 0\n",
    "            log_n_objects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            n_processed_sequences = 0\n",
    "            numerator = early_stopping if early_stopping else len(data_loader.dataset)\n",
    "            denominator = batch_size if batch_size else None\n",
    "            tqdm_total =  numerator // denominator + 1 if denominator else None\n",
    "            if tqdm_total and early_stopping:\n",
    "                tqdm_total = early_stopping\n",
    "            for batch_nr, batch in enumerate(tqdm(data_loader, total=tqdm_total)):\n",
    "                # About minibatch tuple: ['query', 'hits', 'similarity', 'query_labels', 'hits_labels']\n",
    "                sequence = batch.query\n",
    "                labels = batch.query_labels[:, 0]\n",
    "            \n",
    "                inputs = sequence.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Update progress for TensorBoard\n",
    "                current_batch_size = len(inputs)\n",
    "                n_processed_sequences += current_batch_size\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                batch_loss = loss.item()\n",
    "                batch_corrects = torch.sum(preds == labels)\n",
    "                batch_acc = batch_corrects.double() / len(labels)\n",
    "\n",
    "                log_loss += float(batch_loss)\n",
    "                log_corrects += float(batch_corrects)\n",
    "                log_n_objects += len(labels)\n",
    "\n",
    "                if tensorboard_writer is not None and batch_nr % log_interval == 0:\n",
    "                    tensorboard_writer.add_scalar('data/eggnog_crossentropy_loss',\n",
    "                                                  log_loss,\n",
    "                                                  n_processed_sequences)\n",
    "                    tensorboard_writer.add_scalar('data/eggnog_accuracy',\n",
    "                                                  log_corrects / log_n_objects,\n",
    "                                                  n_processed_sequences)\n",
    "                    \n",
    "                    # Reset the log loss/acc variables\n",
    "                    log_loss = 0.\n",
    "                    log_corrects = 0\n",
    "                    log_n_objects = 0\n",
    "\n",
    "                running_loss += batch_loss * inputs.size(0)\n",
    "                running_corrects += batch_corrects\n",
    "                \n",
    "                if early_stopping and n_processed_sequences > early_stopping:\n",
    "                    break\n",
    "\n",
    "            epoch_loss = running_loss / n_processed_sequences\n",
    "            epoch_acc = running_corrects.double() / n_processed_sequences\n",
    "\n",
    "            print(f'{phase} eggnog loss: {epoch_loss:.4f} eggnog acc: {epoch_acc:.4f}\\n')\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    minutes = time_elapsed // 60\n",
    "    seconds = time_elapsed % 60\n",
    "    print(f'Training complete in {minutes:.0f}m {seconds:.0f}s')\n",
    "    print(f'Best val eggnog acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, criterion, data_loader,\n",
    "               batch_size: int = None, early_stopping: int = None,):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    print(f'Test phase')\n",
    "    print('-' * 10)\n",
    "    phase = 'test'\n",
    "    data_loader.dataset.phase = phase\n",
    "    model.eval()   # Set model to evaluate mode (no dropout etc)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    n_processed_sequences = 0\n",
    "    for batch_nr, batch in enumerate(tqdm(data_loader)):\n",
    "        # About minibatch tuple: ['query', 'hits', 'similarity', 'query_labels', 'hits_labels']\n",
    "        sequence = batch.query\n",
    "        labels = batch.query_labels[:, 0]\n",
    "        y_true += [labels.cpu().numpy(), ]\n",
    "\n",
    "        inputs = sequence.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        current_batch_size = len(inputs)\n",
    "        n_processed_sequences += current_batch_size\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_pred += [preds.cpu().numpy(), ]\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # statistics\n",
    "        batch_loss = loss.item()\n",
    "\n",
    "        batch_corrects = torch.sum(preds == labels)\n",
    "        batch_acc = batch_corrects.double() / len(labels)\n",
    "\n",
    "        running_loss += batch_loss * inputs.size(0)\n",
    "        running_corrects += batch_corrects\n",
    "\n",
    "        if early_stopping and n_processed_sequences > early_stopping:\n",
    "            break\n",
    "\n",
    "    epoch_loss = running_loss / n_processed_sequences\n",
    "    epoch_acc = running_corrects.double() / n_processed_sequences\n",
    "\n",
    "    print(f'{phase} eggnog loss: {epoch_loss:.4f} eggnog acc: {epoch_acc:.4f}\\n')\n",
    "\n",
    "    # deep copy the model\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    minutes = time_elapsed // 60\n",
    "    seconds = time_elapsed % 60\n",
    "    print(f'Test complete in {minutes:.0f}m {seconds:.0f}s')\n",
    "    print(f'Test eggnog acc: {epoch_acc:4f}')\n",
    "\n",
    "    return {'model': model,\n",
    "            'y_pred': y_pred,\n",
    "            'y_true': y_true}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of classes (-1 is unknown class, so we must substract 1)\n",
    "n_classes = [np.bincount(col + 1).size - 1 for col in simap_dataset.labels.T]\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 73272\n"
     ]
    }
   ],
   "source": [
    "# Create a PyTorch DataLoader from the SIMAP Siamese dataset\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "data_loader = DataLoader(simap_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         num_workers=num_workers,\n",
    "                         collate_fn=partial(collate_sequences_with_labels, zero_padding=True),\n",
    "                         pin_memory=True)\n",
    "\n",
    "model = DeepFamLike(n_classes=n_classes,\n",
    "                    encoding_dim=10,\n",
    "                    kernel_size=7,\n",
    "                    n_filters=1000,\n",
    "                    dropout=0.2,\n",
    "                    embedding_layer_type='max')\n",
    "\n",
    "# Move to GPU, if available\n",
    "model.to(device)\n",
    "\n",
    "# Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Select an initial learning rate\n",
    "lr = 1e-2\n",
    "\n",
    "# Select the SGD variant for optimization\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=lr)\n",
    "\n",
    "# Setup a scheduler that reduces the learning rate\n",
    "# (Currently, steps are measured as epochs, which may be to large)\n",
    "scheduler = lr_scheduler.StepLR(optimizer,\n",
    "                                step_size=1,\n",
    "                                gamma=0.5,\n",
    "                                last_epoch=-1)\n",
    "\n",
    "# Number of epochs (passes over complete dataset)\n",
    "# if using 'one_random', need several epoch to \n",
    "n_epochs = 8\n",
    "\n",
    "# Print some metrics each interval\n",
    "log_interval = 100\n",
    "\n",
    "# Trainable parameters\n",
    "print(f'Parameters: {count_parameters(model)}')\n",
    "\n",
    "# Tensorboard name\n",
    "tensorboard_exp = f'romanNN-singletask-{class_size}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepFamLike(\n",
       "  (encoding): AminoAcidWordEmbedding(\n",
       "    (embedding): Embedding(27, 10)\n",
       "  )\n",
       "  (conv1): Conv1d(10, 1000, kernel_size=(7,), stride=(1,))\n",
       "  (activation1): SELU()\n",
       "  (dropout1): AlphaDropout(p=0.2, inplace=False)\n",
       "  (embedding1): AdaptiveMaxPool1d(output_size=1)\n",
       "  (classification1): Linear(in_features=1000, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorboard directory: /proj/cube/deepfam/dev/tensorboard/romanNN-singletask-10000_2019-09-04_13-36-04\n",
      "Epoch 0/7\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fd6164c48b4bc38e45d54465d5e98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1014), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train eggnog loss: 0.4999 eggnog acc: 0.9555\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ab2b0a86d544afb9f017f6eb0a777c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=113), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val eggnog loss: 1.2677 eggnog acc: 0.9317\n",
      "\n",
      "Epoch 1/7\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a6f02072994f9c8027febaea9b05f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1014), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train eggnog loss: 0.0383 eggnog acc: 0.9956\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eaf67cdd661474ea738949f85942284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=113), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val eggnog loss: 0.0556 eggnog acc: 0.9950\n",
      "\n",
      "Epoch 2/7\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d81977d027f490a996c8d69acf4b19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1014), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train eggnog loss: 0.0148 eggnog acc: 0.9976\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f36348db7a47fe89a2bef5c0db71a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=113), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val eggnog loss: 0.0010 eggnog acc: 0.9989\n",
      "\n",
      "Epoch 3/7\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38ba9fb6e554775a21f898ed9ed65f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1014), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train eggnog loss: 0.0038 eggnog acc: 0.9995\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01918a39a5c48f1b66572dad702ef18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=113), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val eggnog loss: 0.0079 eggnog acc: 0.9989\n",
      "\n",
      "Epoch 4/7\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13d744d8b0a4b058675139aaf96af61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1014), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train eggnog loss: 0.0006 eggnog acc: 0.9998\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ab7d8b28784d4bbbc885f7b9a331a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=113), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val eggnog loss: 0.0021 eggnog acc: 0.9989\n",
      "\n",
      "Epoch 5/7\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1f77d8db5c45c5aa21e1b6941e52c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1014), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train eggnog loss: 0.0000 eggnog acc: 1.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0ceeccd7424379bf2189ed8ca13fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=113), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val eggnog loss: 0.0029 eggnog acc: 0.9994\n",
      "\n",
      "Epoch 6/7\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879a692d0c2c4f65b5c38c32ff7cbd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1014), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train eggnog loss: 0.0000 eggnog acc: 1.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95a16f14fe7401790bb97faa2e760d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=113), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val eggnog loss: 0.0019 eggnog acc: 0.9989\n",
      "\n",
      "Epoch 7/7\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3658baca5724692bd60a4c66c45e2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1014), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train eggnog loss: 0.0000 eggnog acc: 1.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9644b62a1a1c46e1b41aaac2a5f7a436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=113), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val eggnog loss: 0.0022 eggnog acc: 0.9994\n",
      "\n",
      "Training complete in 2m 10s\n",
      "Best val eggnog acc: 0.999445\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model=model,\n",
    "                    criterion=criterion,\n",
    "                    optimizer=optimizer,\n",
    "                    scheduler=scheduler,\n",
    "                    data_loader=data_loader,\n",
    "                    num_epochs=n_epochs,\n",
    "                    tensorboard_exp=tensorboard_exp,\n",
    "                    batch_size=batch_size,\n",
    "                    early_stopping=None,\n",
    "                    log_interval=log_interval)\n",
    "save_file = tensorboard_exp  + '_' + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "torch.save(model.state_dict(),\n",
    "           f'/proj/cube/deepfam/dev/saves/{save_file}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepFamLike(\n",
       "  (encoding): AminoAcidWordEmbedding(\n",
       "    (embedding): Embedding(27, 10)\n",
       "  )\n",
       "  (conv1): Conv1d(10, 1000, kernel_size=(7,), stride=(1,))\n",
       "  (activation1): SELU()\n",
       "  (dropout1): AlphaDropout(p=0.2, inplace=False)\n",
       "  (embedding1): AdaptiveMaxPool1d(output_size=1)\n",
       "  (classification1): Linear(in_features=1000, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = f'/proj/cube/deepfam/dev/saves/{save_file}.pth'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test phase\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b128241859874232a8b2b17c54878663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test eggnog loss: 0.0078 eggnog acc: 0.9985\n",
      "\n",
      "Test complete in 0m 2s\n",
      "Test eggnog acc: 0.998501\n"
     ]
    }
   ],
   "source": [
    "results = test_model(model, criterion, data_loader, batch_size, early_stopping=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': DeepFamLike(\n",
       "   (encoding): AminoAcidWordEmbedding(\n",
       "     (embedding): Embedding(27, 10)\n",
       "   )\n",
       "   (conv1): Conv1d(10, 1000, kernel_size=(7,), stride=(1,))\n",
       "   (activation1): SELU()\n",
       "   (dropout1): AlphaDropout(p=0.2, inplace=False)\n",
       "   (embedding1): AdaptiveMaxPool1d(output_size=1)\n",
       "   (classification1): Linear(in_features=1000, out_features=2, bias=True)\n",
       " ),\n",
       " 'y_pred': [array([0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]),\n",
       "  array([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1]),\n",
       "  array([1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0]),\n",
       "  array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1]),\n",
       "  array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0]),\n",
       "  array([0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]),\n",
       "  array([1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]),\n",
       "  array([1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1]),\n",
       "  array([1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1]),\n",
       "  array([1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]),\n",
       "  array([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0]),\n",
       "  array([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1]),\n",
       "  array([1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]),\n",
       "  array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0]),\n",
       "  array([1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0]),\n",
       "  array([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1]),\n",
       "  array([0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]),\n",
       "  array([1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]),\n",
       "  array([0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0]),\n",
       "  array([0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1]),\n",
       "  array([0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0]),\n",
       "  array([1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1]),\n",
       "  array([0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]),\n",
       "  array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1]),\n",
       "  array([1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
       "  array([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1]),\n",
       "  array([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]),\n",
       "  array([1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1]),\n",
       "  array([1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       "  array([1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1]),\n",
       "  array([0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0]),\n",
       "  array([1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0]),\n",
       "  array([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]),\n",
       "  array([1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0]),\n",
       "  array([0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1]),\n",
       "  array([0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1]),\n",
       "  array([1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1]),\n",
       "  array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0]),\n",
       "  array([1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0]),\n",
       "  array([1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]),\n",
       "  array([1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1]),\n",
       "  array([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       "  array([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0]),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0]),\n",
       "  array([1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0]),\n",
       "  array([0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0]),\n",
       "  array([1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0]),\n",
       "  array([0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0]),\n",
       "  array([1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1]),\n",
       "  array([1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0]),\n",
       "  array([1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1]),\n",
       "  array([0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]),\n",
       "  array([1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]),\n",
       "  array([1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0]),\n",
       "  array([1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1]),\n",
       "  array([0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0]),\n",
       "  array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0]),\n",
       "  array([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0]),\n",
       "  array([1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]),\n",
       "  array([0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0]),\n",
       "  array([1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1]),\n",
       "  array([1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0]),\n",
       "  array([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]),\n",
       "  array([1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1]),\n",
       "  array([1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0]),\n",
       "  array([1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1]),\n",
       "  array([0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0]),\n",
       "  array([1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1]),\n",
       "  array([1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0]),\n",
       "  array([0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1]),\n",
       "  array([1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]),\n",
       "  array([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0]),\n",
       "  array([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0]),\n",
       "  array([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1]),\n",
       "  array([0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]),\n",
       "  array([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1]),\n",
       "  array([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1]),\n",
       "  array([0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]),\n",
       "  array([1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]),\n",
       "  array([1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0]),\n",
       "  array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       "  array([0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]),\n",
       "  array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0]),\n",
       "  array([0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]),\n",
       "  array([1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0]),\n",
       "  array([0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]),\n",
       "  array([0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0]),\n",
       "  array([1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0]),\n",
       "  array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1]),\n",
       "  array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1]),\n",
       "  array([0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1]),\n",
       "  array([0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1]),\n",
       "  array([0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0]),\n",
       "  array([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1]),\n",
       "  array([1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0]),\n",
       "  array([0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0]),\n",
       "  array([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]),\n",
       "  array([1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0]),\n",
       "  array([1, 1])],\n",
       " 'y_true': [array([0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]),\n",
       "  array([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1]),\n",
       "  array([1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0]),\n",
       "  array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1]),\n",
       "  array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0]),\n",
       "  array([0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]),\n",
       "  array([1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]),\n",
       "  array([1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1]),\n",
       "  array([1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1]),\n",
       "  array([1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]),\n",
       "  array([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0]),\n",
       "  array([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1]),\n",
       "  array([1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]),\n",
       "  array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0]),\n",
       "  array([1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0]),\n",
       "  array([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1]),\n",
       "  array([0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]),\n",
       "  array([1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]),\n",
       "  array([0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0]),\n",
       "  array([0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1]),\n",
       "  array([0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0]),\n",
       "  array([1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1]),\n",
       "  array([0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]),\n",
       "  array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1]),\n",
       "  array([1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
       "  array([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1]),\n",
       "  array([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]),\n",
       "  array([1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1]),\n",
       "  array([1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       "  array([1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1]),\n",
       "  array([0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0]),\n",
       "  array([1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0]),\n",
       "  array([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]),\n",
       "  array([1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0]),\n",
       "  array([0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1]),\n",
       "  array([0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1]),\n",
       "  array([1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1]),\n",
       "  array([1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0]),\n",
       "  array([1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0]),\n",
       "  array([1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]),\n",
       "  array([1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1]),\n",
       "  array([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       "  array([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0]),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0]),\n",
       "  array([1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0]),\n",
       "  array([0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0]),\n",
       "  array([1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0]),\n",
       "  array([0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0]),\n",
       "  array([1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1]),\n",
       "  array([1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0]),\n",
       "  array([1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1]),\n",
       "  array([0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]),\n",
       "  array([1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]),\n",
       "  array([1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0]),\n",
       "  array([1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1]),\n",
       "  array([0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0]),\n",
       "  array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0]),\n",
       "  array([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0]),\n",
       "  array([1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]),\n",
       "  array([0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0]),\n",
       "  array([1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1]),\n",
       "  array([1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0]),\n",
       "  array([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]),\n",
       "  array([1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1]),\n",
       "  array([1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0]),\n",
       "  array([1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1]),\n",
       "  array([0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0]),\n",
       "  array([1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1]),\n",
       "  array([1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0]),\n",
       "  array([0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1]),\n",
       "  array([1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]),\n",
       "  array([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0]),\n",
       "  array([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0]),\n",
       "  array([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1]),\n",
       "  array([0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]),\n",
       "  array([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1]),\n",
       "  array([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1]),\n",
       "  array([0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]),\n",
       "  array([1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]),\n",
       "  array([1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0]),\n",
       "  array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       "  array([0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]),\n",
       "  array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0]),\n",
       "  array([0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]),\n",
       "  array([1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0]),\n",
       "  array([0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]),\n",
       "  array([0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0]),\n",
       "  array([1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0]),\n",
       "  array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1]),\n",
       "  array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1]),\n",
       "  array([0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1]),\n",
       "  array([0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1]),\n",
       "  array([0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0]),\n",
       "  array([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1]),\n",
       "  array([1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0]),\n",
       "  array([0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0]),\n",
       "  array([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]),\n",
       "  array([1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0]),\n",
       "  array([1, 1])]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
